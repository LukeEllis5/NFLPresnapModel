{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f5a101ed-1f65-42ad-8095-fcca59971b79",
   "metadata": {},
   "source": [
    "## Run/Pass Pre-snap Prediction\n",
    "### Metric Track\n",
    "\n",
    "### Overview\n",
    "As advancements in data collection in the NFL have continued to grow, so has the adoption of data science to make predictions. The following model was built to give NFL defenses an advantage against the San Francisco 49ers by producing a probability that the next offensive play will be a designed run or pass play based on their tendencies based on pre-play line-up and game situation. By using this model, defensive coaches will be able to call an audible that will give them an advantage.\n",
    "\n",
    "### Data Source\n",
    "The data was supplied by the NFL and was from weeks 1-6 of the 2023 season. The training data was compressed using gameID and playID and was focused on San Francisco's offensive plays. QB kneels were removed from the dataset. The final training data contained 451 plays and eleven features.\n",
    "\n",
    "### Target Variable\n",
    "The target variable is a Boolean feature that has a value of (1) if it is a designed running play or (0) if it was a pass play. To put an emphasis on play calling, QB scrambles do not count as designed runs.\n",
    "\n",
    "### Model\n",
    "The model is a random forest classifier that uses 10 features to produce the probability that the play will be a designed run play. Because of the imbalance of run to pass plays (194-257), the model uses class weights to prevent biases since there is an imbalance in the data.\n",
    "\n",
    "The model performed well with an accuracy of 80.9% and a ROC AUC of 87.9%. True positives were sought due to the costly nature of calling the wrong play when anticipating a run play. Because of this, precision was sought with a value of 0.81 for both classes.\n",
    "\n",
    "### Feature Selection\n",
    "The following features were selected based on factors that could influence an offense's play-calling. The definitions are from the NFL's Big Data Bowl Dataset Description. The SHAP value is just a ranking.\n",
    "\n",
    "offenseFormation (SHAP 16.51%): Formation used by the possession team. Offensive formations are categorical data that have six options: SHOTGUN, SINGLEBACK, I_FORM, EMPTY, PISTOL, and JUMBO. Offensive formations originally had thirteen null values; these nulls were dropped. The data went through OneHotEncoding.\n",
    "\n",
    "motionSinceLineset (SHAP: 11.20%): Boolean indicating whether the player went in motion after they were initially set at the line on this play. The initial dataset had 1,480 null values; they were filled using a KNN imputer. This feature went through a Binary Encoder before being passed into the training data.\n",
    "\n",
    "receiverAlignment (SHAP 8.26%): Enumerated as 0x0, 1x0, 1x1, 2x0, 2x1, 2x2, 3x0, 3x1, 3x2. Receiver alignment is categorical data that has six options; the data went through OneHotEncoding.\n",
    "\n",
    "down_yardsToGo (SHAP 3.97%): This feature was created by taking the down and multiplying it with the yards to go. This allows for a wider range, punishing later downs with further yards to go. This feature went through StandardScaler.\n",
    "\n",
    "presnap_score_difference (SHAP 3.33%): This feature was created to capture potential play-calling tendencies based on the score difference. If San Francisco is up, the number will be positive; if they are down, the number will be negative. This went through StandardScaler.\n",
    "\n",
    "shiftSinceLineset (SHAP 2.87%): Boolean indicating whether the player shifted since the lineset; Rule: Each player has their own lineset moment, and whether they shift is based on if they move more than 2.5 yards from where they were at their lineset moment. There were thirteen null values; because of the small amount, the null values were dropped. This feature went through a Binary Encoder before being passed into the training data.\n",
    "\n",
    "inMotionAtBallSnap (SHAP 1.57%): Boolean indicating whether the player was in motion at the snap; Rule: If a player is moving faster than 0.62 y/s in the window 0.4 seconds prior to the ball snap and has moved at least 1.2 yards in that window. There were 1,104 null values; they were filled using a KNN imputer. This feature went through a Binary Encoder before being passed into the training data.\n",
    "\n",
    "gameClock_seconds (SHAP 1.45%): From the data feature gameClock, it is the time on the clock of the play (MM:SS). This was converted into seconds and then went through StandardScaler.\n",
    "\n",
    "yardlineNumber (SHAP 0.94%): Yard line at line-of-scrimmage. This went through StandardScaler.\n",
    "\n",
    "quarter (SHAP 0.60%): Game quarter, this went through StandardScaler.\n",
    "\n",
    "We performed a simple correlation to the play result being a run play. As you can see, features that would indicate a run had a higher correlation than features that would indicate a pass.\n",
    "\n",
    "Correlation with playResult:\n",
    "playResult                     1.000000                                   \n",
    "offenseFormation_I_FORM        0.407478                                              \n",
    "receiverAlignment_2x1          0.384195                                            \n",
    "presnap_score_difference       0.282033                                            \n",
    "offenseFormation_SINGLEBACK    0.227010                                            \n",
    "shiftSinceLineset              0.217943                                            \n",
    "offenseFormation_PISTOL        0.144669                                            \n",
    "offenseFormation_JUMBO         0.108878                                            \n",
    "receiverAlignment_1x1          0.076817                                            \n",
    "gameClock_seconds              0.063792                                            \n",
    "receiverAlignment_2x2          0.012063                                            \n",
    "quarter                       -0.055429                                            \n",
    "receiverAlignment_4x1         -0.057986                                            \n",
    "inMotionAtBallSnap            -0.074765                                            \n",
    "yardlineNumber                -0.086802                                            \n",
    "receiverAlignment_3x1         -0.172361                                            \n",
    "receiverAlignment_3x2         -0.270576                                            \n",
    "offenseFormation_EMPTY        -0.278012                                            \n",
    "motionSinceLineset            -0.286902                                            \n",
    "down_yardsToGo                -0.348579                                            \n",
    "offenseFormation_SHOTGUN      -0.379380  \n",
    "\n",
    "### Hyperparameters\n",
    "Using grid search, we were able to fine tune the model to get the best performance focused on the ROC Score. The best hyperparameters were below:\n",
    "\n",
    "classifier__max_depth: 10                                          \n",
    "classifier__max_features: 'sqrt'                               \n",
    "classifier__min_samples_leaf: 1                             \n",
    "classifier__min_samples_split: 10                   \n",
    "classifier__n_estimators: 200              \n",
    "\n",
    "To prevent overfitting we monitored the cross validation scores. The mean cross validation score was 88.5%, which is a strong average. The standard deviation of 1.9% shows us that there is low variability in the model's performance across folds. \n",
    "\n",
    "### Model Performance\n",
    "The model overall performed well with an accuracy score of 80.9% and a ROC AUC of 87.9%. The confusion matrix below will show that the model was able to accurately identify between run and pass plays. Recall was higher at 87% for pass plays compared to 73% for run plays. The f1-score was 84% for pass plays and 77% for run plays. These results allow the defense to have enough confidence in the model where it could give them a competitive advantage.\n",
    "\n",
    "Classification Report:\n",
    "\n",
    "              precision    recall  f1-score   support\n",
    "\n",
    "         0.0       0.81      0.87      0.84        77\n",
    "         1.0       0.81      0.73      0.77        59\n",
    "\n",
    "\n",
    "![ROC Curve](roc_curve.png \"ROC Curve Analysis\")\n",
    "\n",
    "![Confusion Matrix](confusion_matrix.png \"Confusion Matrix\")\n",
    "\n",
    "\n",
    "### Limitations and Assumptions\n",
    "While the accuracy and ROC AUC are high, they could still be higher. The model would need to be continuously retrained every week to capture any new tendencies the San Francisco 49ers might start employing. As the season goes on, the model will need to start dropping earlier weeks of data from the training set or have a larger emphasis on more recent weeks. The model could be enhanced by including features that account for player personnel, such as whether key players like Christian McCaffrey are in the game, as this could influence play-calling tendencies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "547b644a-30ab-4e72-8bac-4bfec1f58b30",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Correlation with playResult:\n",
      "playResult                     1.000000\n",
      "offenseFormation_I_FORM        0.407478\n",
      "receiverAlignment_2x1          0.384195\n",
      "presnap_score_difference       0.282033\n",
      "offenseFormation_SINGLEBACK    0.227010\n",
      "shiftSinceLineset              0.217943\n",
      "offenseFormation_PISTOL        0.144669\n",
      "offenseFormation_JUMBO         0.108878\n",
      "receiverAlignment_1x1          0.076817\n",
      "gameClock_seconds              0.063792\n",
      "receiverAlignment_2x2          0.012063\n",
      "quarter                       -0.055429\n",
      "receiverAlignment_4x1         -0.057986\n",
      "inMotionAtBallSnap            -0.074765\n",
      "yardlineNumber                -0.086802\n",
      "receiverAlignment_3x1         -0.172361\n",
      "receiverAlignment_3x2         -0.270576\n",
      "offenseFormation_EMPTY        -0.278012\n",
      "motionSinceLineset            -0.286902\n",
      "down_yardsToGo                -0.348579\n",
      "offenseFormation_SHOTGUN      -0.379380\n",
      "Name: playResult, dtype: float64\n",
      "Training model...\n",
      "Fitting 5 folds for each of 324 candidates, totalling 1620 fits\n",
      "\n",
      "Best parameters: {'classifier__max_depth': 10, 'classifier__max_features': 'sqrt', 'classifier__min_samples_leaf': 1, 'classifier__min_samples_split': 10, 'classifier__n_estimators': 200}\n",
      "\n",
      "Model Evaluation Metrics:\n",
      "Accuracy: 0.809\n",
      "ROC AUC: 0.879\n",
      "CV Scores: [0.88658777 0.84917044 0.90397185 0.88888889 0.89777328]\n",
      "Mean CV score: 0.885\n",
      "Standard Deviation of CV scores: 0.019\n",
      "\n",
      "Confusion Matrix:\n",
      "[[67 10]\n",
      " [16 43]]\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.81      0.87      0.84        77\n",
      "         1.0       0.81      0.73      0.77        59\n",
      "\n",
      "    accuracy                           0.81       136\n",
      "   macro avg       0.81      0.80      0.80       136\n",
      "weighted avg       0.81      0.81      0.81       136\n",
      "\n",
      "\n",
      "Feature Ranking Based on SHAP Values (Grouped):\n",
      "1. offenseFormation (0.1651)\n",
      "2. motionSinceLineset (0.1120)\n",
      "3. receiverAlignment (0.0826)\n",
      "4. down_yardsToGo (0.0397)\n",
      "5. presnap_score_difference (0.0333)\n",
      "6. shiftSinceLineset (0.0287)\n",
      "7. inMotionAtBallSnap (0.0157)\n",
      "8. gameClock_seconds (0.0145)\n",
      "9. yardlineNumber (0.0094)\n",
      "10. quarter (0.0060)\n"
     ]
    }
   ],
   "source": [
    "#Appendix\n",
    "\n",
    "#Import necessary packages\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import shap\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, cross_val_score, learning_curve, StratifiedKFold\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from category_encoders import BinaryEncoder\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report, roc_auc_score, roc_curve, auc\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "from sklearn.impute import KNNImputer\n",
    "\n",
    "\n",
    "\n",
    "# Data Import\n",
    "plays_columns = ['gameId', 'playId', 'passResult', 'offenseFormation', 'down', 'yardsToGo', 'receiverAlignment', 'yardlineNumber',\n",
    "                 'gameClock', 'quarter', 'preSnapHomeScore', 'preSnapVisitorScore']\n",
    "plays_data = pd.read_csv('/Users/lukeellis/Documents/NFL/nfl-big-data-bowl-2025/plays.csv', usecols=plays_columns)\n",
    "games_data = pd.read_csv('/Users/lukeellis/Documents/NFL/nfl-big-data-bowl-2025/games.csv')\n",
    "player_play_data = pd.read_csv('/Users/lukeellis/Documents/NFL/nfl-big-data-bowl-2025/player_play.csv', usecols=['nflId', 'gameId', 'playId', 'teamAbbr', 'hadRushAttempt', 'inMotionAtBallSnap', 'shiftSinceLineset', 'motionSinceLineset'])\n",
    "players_data = pd.read_csv('/Users/lukeellis/Documents/NFL/nfl-big-data-bowl-2025/players.csv')\n",
    "teams_data = pd.read_csv('/Users/lukeellis/Documents/NFL/nfl-big-data-bowl-2025/games.csv', usecols=['gameId', 'homeTeamAbbr', 'visitorTeamAbbr'])\n",
    "\n",
    "# Data Merging\n",
    "player_play_merged = player_play_data.merge(players_data[['nflId', 'position']], on='nflId', how='left')\n",
    "play_game_merged = player_play_merged.merge(plays_data, on=['gameId', 'playId'], how='left')\n",
    "master_data = play_game_merged.merge(teams_data, on='gameId', how='left')\n",
    "\n",
    "# Data Filtering and Preprocessing\n",
    "master_data = master_data[(master_data['teamAbbr'] == 'SF') & (master_data['position'].isin(['QB', 'RB', 'WR', 'TE', 'FB']))]\n",
    "master_data['presnap_score_difference'] = np.where(master_data['homeTeamAbbr'] == 'SF', \n",
    "                                                   master_data['preSnapHomeScore'] - master_data['preSnapVisitorScore'],\n",
    "                                                   master_data['preSnapVisitorScore'] - master_data['preSnapHomeScore'])\n",
    "\n",
    "master_data = master_data[master_data['offenseFormation'] != 'None'].dropna(subset=['shiftSinceLineset', 'offenseFormation'])\n",
    "#Create target value\n",
    "master_data['playResult'] = master_data['passResult'].apply(lambda x: 1 if pd.isna(x) else 0)\n",
    "\n",
    "# Data Aggregation\n",
    "data_aggregated = master_data.groupby(['gameId', 'playId'], as_index=False).agg({\n",
    "    'hadRushAttempt': 'max',\n",
    "    'inMotionAtBallSnap': 'max',\n",
    "    'shiftSinceLineset': 'max',\n",
    "    'motionSinceLineset': 'max',\n",
    "    'offenseFormation': 'first',\n",
    "    'playResult': 'first',\n",
    "    'down': 'first',\n",
    "    'passResult': 'first',     \n",
    "    'yardsToGo': 'first',\n",
    "    'receiverAlignment': 'first',\n",
    "    'gameClock': 'first',\n",
    "    'yardlineNumber': 'first',\n",
    "    'quarter': 'first',\n",
    "    'presnap_score_difference': 'first'\n",
    "})\n",
    "data_aggregated['down_yardsToGo'] = data_aggregated['down'] * data_aggregated['yardsToGo']\n",
    "\n",
    "#Drop unnecessary columns\n",
    "columns_to_drop = ['gameId', 'playId', 'hadRushAttempt','passResult', 'down', 'yardsToGo']\n",
    "data_aggregated = data_aggregated.drop(columns=columns_to_drop)\n",
    "\n",
    "#Convert feature to seconds\n",
    "def time_to_seconds(time_str):\n",
    "    if pd.isna(time_str):\n",
    "        return np.nan\n",
    "    minutes, seconds = map(int, time_str.split(':'))\n",
    "    return minutes * 60 + seconds\n",
    "\n",
    "\n",
    "data_aggregated['gameClock_seconds'] = data_aggregated['gameClock'].apply(time_to_seconds)\n",
    "data_aggregated = data_aggregated.drop('gameClock', axis=1)\n",
    "\n",
    "# Encoding and Feature Selection\n",
    "categorical_features = ['offenseFormation', 'receiverAlignment']\n",
    "data_encoded = pd.get_dummies(data_aggregated, columns=categorical_features)\n",
    "\n",
    "# Correlation Analysis\n",
    "corr = data_encoded.corr()['playResult'].sort_values(ascending=False)\n",
    "print(\"Correlation with playResult:\")\n",
    "print(corr)\n",
    "\n",
    "\n",
    "# KNN imputate to fix remaining null values\n",
    "def knn_impute(df, target_column, n_neighbors=5):\n",
    "    numerical_df = df.select_dtypes(include=['float64', 'int64', 'bool'])\n",
    "    knn_imputer = KNNImputer(n_neighbors=n_neighbors)\n",
    "    imputed_data = knn_imputer.fit_transform(numerical_df)\n",
    "    imputed_df = pd.DataFrame(imputed_data, columns=numerical_df.columns)\n",
    "    df[numerical_df.columns] = imputed_df\n",
    "    return df\n",
    "\n",
    "data_aggregated = knn_impute(data_aggregated, 'inMotionAtBallSnap')\n",
    "data_aggregated = knn_impute(data_aggregated, 'motionSinceLineset')\n",
    "\n",
    "# Model Preparation\n",
    "X = data_aggregated.drop('playResult', axis=1)\n",
    "y = data_aggregated['playResult']\n",
    "\n",
    "\n",
    "# Seperate features\n",
    "numeric_features = ['down_yardsToGo', 'yardlineNumber', 'gameClock_seconds', 'presnap_score_difference', 'quarter']\n",
    "categorical_features = ['offenseFormation', 'receiverAlignment']\n",
    "binary_features = ['shiftSinceLineset', 'motionSinceLineset', 'inMotionAtBallSnap']\n",
    "\n",
    "# Preprocessing Pipeline\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', StandardScaler(), numeric_features),\n",
    "        ('cat', OneHotEncoder(sparse_output=False, handle_unknown='ignore'), categorical_features),\n",
    "        ('motion', BinaryEncoder(), binary_features)\n",
    "    ],\n",
    "    remainder='passthrough'\n",
    ")\n",
    "\n",
    "# Model Pipeline\n",
    "class_weights = compute_class_weight('balanced', classes=[0, 1], y=y)\n",
    "class_weights_dict = {i: weight for i, weight in enumerate(class_weights)}\n",
    "\n",
    "pipeline = Pipeline([\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('classifier', RandomForestClassifier(class_weight=class_weights_dict, random_state=42))\n",
    "])\n",
    "\n",
    "# Hyperparameter Tuning\n",
    "param_grid = {\n",
    "    'classifier__n_estimators': [100, 200, 300],\n",
    "    'classifier__max_depth': [None, 10, 20, 30],\n",
    "    'classifier__min_samples_split': [2, 5, 10],\n",
    "    'classifier__min_samples_leaf': [1, 2, 4],\n",
    "    'classifier__max_features': ['sqrt', 'log2', None]\n",
    "}\n",
    "\n",
    "grid_search = GridSearchCV(pipeline, param_grid, cv=5, scoring='roc_auc', n_jobs=-1, verbose=1)\n",
    "\n",
    "# Split the data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "# Train model\n",
    "print(\"Training model...\")\n",
    "grid_search.fit(X_train, y_train)\n",
    "best_model = grid_search.best_estimator_\n",
    "print(\"\\nBest parameters:\", grid_search.best_params_)\n",
    "\n",
    "# Predictions\n",
    "y_pred_proba = best_model.predict_proba(X_test)[:, 1]\n",
    "y_pred = best_model.predict(X_test)\n",
    "\n",
    "# Metrics\n",
    "metrics = {\n",
    "    'Accuracy': accuracy_score(y_test, y_pred),\n",
    "    'ROC AUC': roc_auc_score(y_test, y_pred_proba)\n",
    "}\n",
    "\n",
    "#Using Stratified Cross Validation to prevent overfitting\n",
    "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "cv_scores = cross_val_score(best_model, X, y, cv=cv, scoring='roc_auc')\n",
    "\n",
    "metrics['CV Scores'] = cv_scores\n",
    "\n",
    "print(\"\\nModel Evaluation Metrics:\")\n",
    "for metric, value in metrics.items():\n",
    "    if metric != 'CV Scores':\n",
    "        print(f\"{metric}: {value:.3f}\")\n",
    "    else:\n",
    "        print(f\"{metric}: {value}\")\n",
    "        print(f\"Mean CV score: {value.mean():.3f}\")\n",
    "        print(f\"Standard Deviation of CV scores: {value.std():.3f}\")\n",
    "\n",
    "print(\"\\nConfusion Matrix:\")\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "# ROC Curve\n",
    "plt.figure(figsize=(5, 3))\n",
    "fpr, tpr, _ = roc_curve(y_test, y_pred_proba)\n",
    "roc_auc = auc(fpr, tpr)\n",
    "plt.plot(fpr, tpr, color='darkorange', lw=2, label=f'ROC curve (AUC = {roc_auc:.2f})')\n",
    "plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('ROC Curve')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.savefig('roc_curve.png', dpi=300, bbox_inches='tight')\n",
    "plt.close()\n",
    "\n",
    "\n",
    "\n",
    "# List of base features\n",
    "base_features = [\n",
    "    'shiftSinceLineset', 'motionSinceLineset', 'inMotionAtBallSnap',\n",
    "    'offenseFormation', 'receiverAlignment', 'down_yardsToGo', 'quarter',\n",
    "    'yardlineNumber', 'gameClock_seconds', 'presnap_score_difference'\n",
    "]\n",
    "feature_names = best_model.named_steps['preprocessor'].get_feature_names_out().tolist()\n",
    "\n",
    "\n",
    "# Transform X_test using the preprocessor\n",
    "X_test_transformed = best_model.named_steps['preprocessor'].transform(X_test)\n",
    "\n",
    "# SHAP Explainer\n",
    "explainer = shap.TreeExplainer(best_model.named_steps['classifier'])  # Adjust 'classifier' step if different\n",
    "shap_values = explainer.shap_values(X_test_transformed)\n",
    "\n",
    "# Aggregate SHAP values across the class dimension (e.g., take mean absolute values)\n",
    "shap_values = np.abs(shap_values).mean(axis=2)  # Shape becomes (n_samples, n_features)\n",
    "\n",
    "# Calculate mean absolute SHAP values across samples\n",
    "mean_abs_shap_values = shap_values.mean(axis=0)  # Shape becomes (n_features,)\n",
    "\n",
    "# Verify alignment with feature names\n",
    "if len(mean_abs_shap_values) != len(feature_names):\n",
    "    raise ValueError(f\"Shape mismatch: {len(mean_abs_shap_values)} SHAP values vs. {len(feature_names)} feature names.\")\n",
    "\n",
    "# Map each feature name to its base category\n",
    "def map_to_base_feature(feature_name):\n",
    "    for base_feature in base_features:\n",
    "        if base_feature in feature_name:\n",
    "            return base_feature\n",
    "    return feature_name  # If no match, return the original name\n",
    "\n",
    "mapped_features = [map_to_base_feature(name) for name in feature_names]\n",
    "\n",
    "# Group SHAP values by the base feature\n",
    "shap_df = pd.DataFrame({'Feature': mapped_features, 'SHAP Value': mean_abs_shap_values})\n",
    "grouped_shap = shap_df.groupby('Feature')['SHAP Value'].sum().sort_values(ascending=False)\n",
    "\n",
    "# Print grouped feature ranking\n",
    "print(\"\\nFeature Ranking Based on SHAP Values (Grouped):\")\n",
    "for rank, (feature_name, shap_value) in enumerate(grouped_shap.items(), 1):\n",
    "    print(f\"{rank}. {feature_name} ({shap_value:.4f})\")\n",
    "\n",
    "#Create Confusion Matrix\n",
    "\n",
    "conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "conf_matrix_normalized = conf_matrix.astype('float') / conf_matrix.sum(axis=1, keepdims=True)\n",
    "\n",
    "# Plot the heatmap\n",
    "plt.figure(figsize=(8, 6))\n",
    "ax = sns.heatmap(conf_matrix_normalized, annot=False, fmt='.2%', cmap='Blues',\n",
    "                 xticklabels=['Predicted Run', 'Predicted Pass'], \n",
    "                 yticklabels=['Actual Run', 'Actual Pass'])\n",
    "\n",
    "# Titles and labels\n",
    "plt.title('Confusion Matrix', fontsize=14)\n",
    "\n",
    "# Annotate each cell with count and percentage\n",
    "for i in range(conf_matrix.shape[0]):\n",
    "    for j in range(conf_matrix.shape[1]):\n",
    "        count = conf_matrix[i, j]\n",
    "        percentage = conf_matrix_normalized[i, j]\n",
    "        text_color = \"white\" if (i == 0 and j == 0) else \"black\"  # White text for upper-left cell only\n",
    "        ax.text(j + 0.5, i + 0.5, f\"{count}\\n({percentage:.2%})\",\n",
    "                ha=\"center\", va=\"center\", color=text_color, fontsize=10)\n",
    "\n",
    "# Save and show plot\n",
    "plt.savefig('confusion_matrix.png', dpi=300, bbox_inches='tight')\n",
    "plt.close()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
